[W903 09:41:56.826892334 Utils.hpp:137] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function operator())
INFO:root:--------------- Versions ---------------
fatal: not a git repository (or any parent up to mount point /)
Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).
INFO:root:Torch: 2.7.0+cu126
INFO:root:----------------------------------------
INFO:root:------------------ Configuration ------------------
INFO:root:Configuration file: /home/choutilin1/v250508/config/sfnonet.yaml
INFO:root:Configuration name: vars33_H
INFO:root:valid_autoreg_steps 180
INFO:root:max_epochs 29
INFO:root:add_grid True
INFO:root:channel_names ['u10m', 'v10m', 'mslp', 't2m', 'sp', 'u1000', 'v1000', 'z1000', 't850', 'u850', 'v850', 'z850', 'r850', 't500', 'u500', 'v500', 'z500', 'r500', 'z50', 'tcwv', 'sst', 'snsh', 'snlh', 'snsw', 'snlw']
INFO:root:num_layers 8
INFO:root:loss weighted absolute squared geometric l2
INFO:root:channel_weights auto
INFO:root:batch_size 1
INFO:root:optimizer_type AdamW
INFO:root:metadata_json_path /work/choutilin1/out_vars33/vars33.json
INFO:root:train_data_path /work/choutilin1/data_4d/train
INFO:root:valid_data_path /work/choutilin1/data_4d/test
INFO:root:inf_data_path /work/choutilin1/data_4d/inf
INFO:root:global_means_path /work/choutilin1/out_vars33/global_means_2011-2016.npy
INFO:root:global_stds_path /work/choutilin1/out_vars33/global_stds_2011-2016.npy
INFO:root:time_means_path /work/choutilin1/out_vars33/time_means_2011-2016.npy
INFO:root:exp_dir /work/choutilin1/out_vars33
INFO:root:n_eval_samples 1460
INFO:root:n_train_samples_per_epoch 7300
INFO:root:wandb_group sfno_linear_73chq_sc3_layers8_edim384_asgl2
INFO:root:embed_dim 384
INFO:root:scale_factor 3
INFO:root:hard_thresholding_fraction 1.0
INFO:root:n_years 1
INFO:root:img_shape_y 1440
INFO:root:img_shape_x 721
INFO:root:min_path 
INFO:root:max_path 
INFO:root:time_diff_means_path 
INFO:root:time_diff_stds_path 
INFO:root:nettype SFNO
INFO:root:model_grid_type equiangular
INFO:root:sht_grid_type legendre-gauss
INFO:root:filter_type linear
INFO:root:complex_activation real
INFO:root:normalization_layer instance_norm
INFO:root:use_mlp True
INFO:root:mlp_mode serial
INFO:root:mlp_ratio 2
INFO:root:separable False
INFO:root:operator_type dhconv
INFO:root:activation_function gelu
INFO:root:pos_embed none
INFO:root:lr 0.001
INFO:root:weight_decay 0.0
INFO:root:scheduler StepLR
INFO:root:scheduler_T_max 70
INFO:root:scheduler_factor 0.1
INFO:root:scheduler_patience 10
INFO:root:scheduler_step_size 100
INFO:root:scheduler_gamma 0.5
INFO:root:lr_warmup_steps 0
INFO:root:verbose False
INFO:root:wireup_info mpi
INFO:root:wireup_store tcp
INFO:root:num_data_workers 1
INFO:root:num_visualization_workers 1
INFO:root:dt 1
INFO:root:n_history 0
INFO:root:prediction_type iterative
INFO:root:prediction_length 35
INFO:root:n_initial_conditions 5
INFO:root:ics_type specify_number
INFO:root:save_raw_forecasts True
INFO:root:save_channel False
INFO:root:masked_acc False
INFO:root:maskpath None
INFO:root:perturb False
INFO:root:add_noise False
INFO:root:noise_std 0.0
INFO:root:target default
INFO:root:normalize_residual False
INFO:root:normalization zscore
INFO:root:gridtype sinusoidal
INFO:root:grid_num_frequencies 16
INFO:root:roll False
INFO:root:add_zenith True
INFO:root:add_orography True
INFO:root:orography_path /work/lkkbox945/models/makani/v250508/datasets/source/invariant/orography.nc
INFO:root:add_landmask True
INFO:root:landmask_path /home/choutilin1/makani/datasets/source/invariant/land_sea_mask.nc
INFO:root:finetune False
INFO:root:log_to_screen True
INFO:root:log_to_wandb False
INFO:root:log_video 0
INFO:root:save_checkpoint legacy
INFO:root:optimizer_beta1 0.9
INFO:root:optimizer_beta2 0.95
INFO:root:optimizer_max_grad_norm 32
INFO:root:crop_size_x None
INFO:root:crop_size_y None
INFO:root:wandb_name None
INFO:root:wandb_project sfno architecture validation
INFO:root:wandb_entity choutilin-national-taiwan-university
INFO:root:epsilon_factor 0
INFO:root:fin_parallel_size 1
INFO:root:fout_parallel_size 1
INFO:root:h_parallel_size 1
INFO:root:w_parallel_size 1
INFO:root:model_parallel_sizes [1, 1, 1, 1]
INFO:root:model_parallel_names ['h', 'w', 'fin', 'fout']
INFO:root:parameters_reduction_buffer_count 1
INFO:root:load_checkpoint legacy
INFO:root:world_size 1
INFO:root:global_batch_size 1
INFO:root:experiment_dir /work/choutilin1/out_vars33/vars33_H/99
INFO:root:checkpoint_path /work/choutilin1/out_vars33/vars33_H/99/training_checkpoints/ckpt_mp{mp_rank}.tar
INFO:root:best_checkpoint_path /work/choutilin1/out_vars33/vars33_H/99/training_checkpoints/best_ckpt_mp{mp_rank}.tar
INFO:root:resuming False
INFO:root:amp_mode none
INFO:root:jit_mode none
INFO:root:cuda_graph_mode none
INFO:root:skip_validation False
INFO:root:enable_odirect False
INFO:root:checkpointing 0
INFO:root:enable_synthetic_data False
INFO:root:split_data_channels False
INFO:root:print_timings_frequency -1
INFO:root:multistep_count 1
INFO:root:n_future 0
INFO:root:enable_benchy False
INFO:root:disable_ddp False
INFO:root:enable_grad_anomaly_detection False
INFO:root:wandb_dir /work/choutilin1/out_vars33/vars33_H/99
INFO:root:_yaml_filename /home/choutilin1/v250508/config/sfnonet.yaml
INFO:root:_config_name vars33_H
INFO:root:---------------------------------------------------
INFO:root:Using channel names: ['u10m', 'v10m', 'mslp', 't2m', 'sp', 'u1000', 'v1000', 'z1000', 't850', 'u850', 'v850', 'z850', 'r850', 't500', 'u500', 'v500', 'z500', 'r500', 'z50', 'tcwv', 'sst', 'snsh', 'snlh', 'snsw', 'snlw']
INFO:root:initializing data loader
INFO:root:nvmlDeviceGetMemoryInfo used log1: 8.5421142578125 GB (4.76837158203125e-07 GB for pytorch)
INFO:root:Getting file stats from /work/choutilin1/data_4d/train/2011.h5
INFO:root:Average number of samples per year: 1460.8
INFO:root:Found data at path ['/work/choutilin1/data_4d/train']. Number of examples: 7304. Full image Shape: 721 x 1440 x 33. Read Shape: 721 x 1440 x 25
INFO:root:Using 7304 from the total number of available samples with 7300 samples per epoch (corresponds to 7300 steps for 1 shards with local batch size 1)
INFO:root:Delta t: 6 hours
INFO:root:Including 6 hours of past history in training at a frequency of 6 hours
INFO:root:Including 6 hours of future targets in training at a frequency of 6 hours
INFO:root:nvmlDeviceGetMemoryInfo used log2: 10.45770263671875 GB (0.20305776596069336 GB for pytorch)
INFO:root:Getting file stats from /work/choutilin1/data_4d/test/2016.h5
INFO:root:Average number of samples per year: 1460.0
INFO:root:Found data at path ['/work/choutilin1/data_4d/test']. Number of examples: 1464. Full image Shape: 721 x 1440 x 33. Read Shape: 721 x 1440 x 25
INFO:root:Using 1460 from the total number of available samples with 1460 samples per epoch (corresponds to 1460 steps for 1 shards with local batch size 1)
INFO:root:Delta t: 6 hours
INFO:root:Including 6 hours of past history in training at a frequency of 6 hours
INFO:root:Including 1086 hours of future targets in training at a frequency of 6 hours
INFO:root:data loader initialized
INFO:root:nvmlDeviceGetMemoryInfo used log3: 15.035400390625 GB (1.19804048538208 GB for pytorch)
/home/choutilin1/makani/makani/mpu/layers.py:175: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  def forward(ctx, X, weight, bias, inp_group_name, out_group_name):
/home/choutilin1/makani/makani/mpu/layers.py:197: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(ctx, grad_out):
INFO:root:Auxiliary channel names: ['xzen', 'xgrlat', 'xgrlon', 'xoro', 'xlsml', 'xlsms']
INFO:root:nvmlDeviceGetMemoryInfo used log4: 17.724853515625 GB (3.8833189010620117 GB for pytorch)
INFO:root:
SingleStepWrapper(
  (preprocessor): Preprocessor2D()
  (model): SphericalFourierNeuralOperatorNet(
    (trans_down): RealSHT(
      nlat=721, nlon=1440,
       lmax=240, mmax=241,
       grid=equiangular, csphase=True
    )
    (itrans_up): InverseRealSHT(
      nlat=721, nlon=1440,
       lmax=240, mmax=241,
       grid=equiangular, csphase=True
    )
    (trans): RealSHT(
      nlat=240, nlon=480,
       lmax=240, mmax=241,
       grid=legendre-gauss, csphase=True
    )
    (itrans): InverseRealSHT(
      nlat=240, nlon=480,
       lmax=240, mmax=241,
       grid=legendre-gauss, csphase=True
    )
    (encoder): EncoderDecoder(
      (fwd): Sequential(
        (0): Conv2d(61, 384, kernel_size=(1, 1), stride=(1, 1))
        (1): GELU(approximate='none')
        (2): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
    )
    (pos_drop): Identity()
    (blocks): ModuleList(
      (0): FourierNeuralOperatorBlock(
        (norm0): InstanceNorm2d(384, eps=1e-06, momentum=0.1, affine=True, track_running_stats=False)
        (filter): SpectralFilterLayer(
          (filter): SpectralConv(
            (forward_transform): RealSHT(
              nlat=721, nlon=1440,
               lmax=240, mmax=241,
               grid=equiangular, csphase=True
            )
            (inverse_transform): InverseRealSHT(
              nlat=240, nlon=480,
               lmax=240, mmax=241,
               grid=legendre-gauss, csphase=True
            )
          )
        )
        (act_layer0): GELU(approximate='none')
        (norm1): InstanceNorm2d(384, eps=1e-06, momentum=0.1, affine=True, track_running_stats=False)
        (outer_skip): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (mlp): MLP(
          (fwd): Sequential(
            (0): Conv2d(384, 768, kernel_size=(1, 1), stride=(1, 1))
            (1): GELU(approximate='none')
            (2): Identity()
            (3): Conv2d(768, 384, kernel_size=(1, 1), stride=(1, 1))
            (4): Identity()
          )
        )
        (drop_path): Identity()
      )
      (1-6): 6 x FourierNeuralOperatorBlock(
        (norm0): InstanceNorm2d(384, eps=1e-06, momentum=0.1, affine=True, track_running_stats=False)
        (filter): SpectralFilterLayer(
          (filter): SpectralConv(
            (forward_transform): RealSHT(
              nlat=240, nlon=480,
               lmax=240, mmax=241,
               grid=legendre-gauss, csphase=True
            )
            (inverse_transform): InverseRealSHT(
              nlat=240, nlon=480,
               lmax=240, mmax=241,
               grid=legendre-gauss, csphase=True
            )
          )
        )
        (act_layer0): GELU(approximate='none')
        (norm1): InstanceNorm2d(384, eps=1e-06, momentum=0.1, affine=True, track_running_stats=False)
        (outer_skip): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (mlp): MLP(
          (fwd): Sequential(
            (0): Conv2d(384, 768, kernel_size=(1, 1), stride=(1, 1))
            (1): GELU(approximate='none')
            (2): Identity()
            (3): Conv2d(768, 384, kernel_size=(1, 1), stride=(1, 1))
            (4): Identity()
          )
        )
        (drop_path): Identity()
      )
      (7): FourierNeuralOperatorBlock(
        (norm0): InstanceNorm2d(384, eps=1e-06, momentum=0.1, affine=True, track_running_stats=False)
        (filter): SpectralFilterLayer(
          (filter): SpectralConv(
            (forward_transform): RealSHT(
              nlat=240, nlon=480,
               lmax=240, mmax=241,
               grid=legendre-gauss, csphase=True
            )
            (inverse_transform): InverseRealSHT(
              nlat=721, nlon=1440,
               lmax=240, mmax=241,
               grid=equiangular, csphase=True
            )
          )
        )
        (act_layer0): GELU(approximate='none')
        (norm1): InstanceNorm2d(384, eps=1e-06, momentum=0.1, affine=True, track_running_stats=False)
        (outer_skip): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (mlp): MLP(
          (fwd): Sequential(
            (0): Conv2d(384, 768, kernel_size=(1, 1), stride=(1, 1))
            (1): GELU(approximate='none')
            (2): Identity()
            (3): Conv2d(768, 384, kernel_size=(1, 1), stride=(1, 1))
            (4): Identity()
          )
        )
        (drop_path): Identity()
      )
    )
    (decoder): EncoderDecoder(
      (fwd): Sequential(
        (0): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))
        (1): GELU(approximate='none')
        (2): Conv2d(384, 25, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
    )
    (residual_transform): Conv2d(61, 25, kernel_size=(1, 1), stride=(1, 1), bias=False)
  )
)
INFO:root:nvmlDeviceGetMemoryInfo used log5: 17.724853515625 GB (3.8833189010620117 GB for pytorch)
INFO:root:using AdamW
/home/choutilin1/makani/makani/utils/trainer.py:512: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  self.gscaler = amp.GradScaler(enabled=(self.amp_dtype == torch.float16))
[rank0]:[W903 09:42:27.622185256 Utils.hpp:112] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function operator())
INFO:root:Number of trainable model parameters: 289365493
INFO:root:nvmlDeviceGetMemoryInfo used log6: 19.978759765625 GB (6.129299163818359 GB for pytorch)
INFO:root:Scaffolding memory high watermark: 19.978759765625 GB (6.129299163818359 GB for pytorch)
INFO:root:Starting Training Loop...
Training progress  :   0%|          | 0/7300 [00:00<?, ?it/s]/home/choutilin1/makani/makani/utils/trainer.py:750: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with amp.autocast(enabled=self.amp_enabled, dtype=self.amp_dtype):
Training progress  :   0%|          | 0/7300 [00:00<?, ?it/s]
[rank0]: Traceback (most recent call last):
[rank0]:   File "/home/choutilin1/makani/makani/train.py", line 177, in <module>
[rank0]:     trainer.train()
[rank0]:   File "/home/choutilin1/makani/makani/utils/trainer.py", line 647, in train
[rank0]:     train_time, train_data_gb, train_logs = self.train_one_epoch()
[rank0]:   File "/home/choutilin1/makani/makani/utils/trainer.py", line 751, in train_one_epoch
[rank0]:     pred = self.model_train(inp)
[rank0]:   File "/work/choutilin1/.conda/envs/makani/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
[rank0]:     return self._call_impl(*args, **kwargs)
[rank0]:   File "/work/choutilin1/.conda/envs/makani/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
[rank0]:     return forward_call(*args, **kwargs)
[rank0]:   File "/work/choutilin1/.conda/envs/makani/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1637, in forward
[rank0]:     else self._run_ddp_forward(*inputs, **kwargs)
[rank0]:   File "/work/choutilin1/.conda/envs/makani/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1464, in _run_ddp_forward
[rank0]:     return self.module(*inputs, **kwargs)  # type: ignore[index]
[rank0]:   File "/work/choutilin1/.conda/envs/makani/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
[rank0]:     return self._call_impl(*args, **kwargs)
[rank0]:   File "/work/choutilin1/.conda/envs/makani/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
[rank0]:     return forward_call(*args, **kwargs)
[rank0]:   File "/home/choutilin1/makani/makani/models/stepper.py", line 40, in forward
[rank0]:     raise Exception
[rank0]: Exception
E0903 09:42:39.841000 667378 site-packages/torch/distributed/elastic/multiprocessing/api.py:874] failed (exitcode: 1) local_rank: 0 (pid: 667468) of binary: /work/choutilin1/.conda/envs/makani/bin/python3.10
Traceback (most recent call last):
  File "/work/choutilin1/.conda/envs/makani/bin/torchrun", line 8, in <module>
    sys.exit(main())
  File "/work/choutilin1/.conda/envs/makani/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 355, in wrapper
    return f(*args, **kwargs)
  File "/work/choutilin1/.conda/envs/makani/lib/python3.10/site-packages/torch/distributed/run.py", line 892, in main
    run(args)
  File "/work/choutilin1/.conda/envs/makani/lib/python3.10/site-packages/torch/distributed/run.py", line 883, in run
    elastic_launch(
  File "/work/choutilin1/.conda/envs/makani/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 139, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/work/choutilin1/.conda/envs/makani/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 270, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
/home/choutilin1/makani/makani/train.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2025-09-03_09:42:39
  host      : hgpn02
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 667468)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
